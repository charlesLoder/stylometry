{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f732827a",
   "metadata": {},
   "source": [
    "# Generating a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0f42fd",
   "metadata": {},
   "source": [
    "The first part of the fine tuning process is generating a dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930c1f2",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create an \"instruction-based\" fine tuning dataset using metadata accessed via IIIF,\n",
    "which will be uploaded to Huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f1c3d2",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135732f5",
   "metadata": {},
   "source": [
    "Ensure you have a [Huggingface](https://huggingface.co) account.\n",
    "\n",
    "Create a [token](https://huggingface.co/docs/hub/en/security-tokens) with the minimum settings of:\n",
    "- Read access to contents of all repos under your personal namespace\n",
    "- Read access to contents of all public gated repos you can access\n",
    "- Write access to contents/settings of all repos under your personal namespace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192c8b06",
   "metadata": {},
   "source": [
    "## Collecting Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caa5b3d8",
   "metadata": {},
   "source": [
    "The first step is to use `loam-iiif` fetch manifests from a IIIF Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b90316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Found 5000 manifests\n"
     ]
    }
   ],
   "source": [
    "from loam_iiif import iiif\n",
    "\n",
    "client = iiif.IIIFClient()\n",
    "\n",
    "# Berkeley Folk Music Festival\n",
    "collection_url = \"https://api.dc.library.northwestern.edu/api/v2/collections/18ec4c6b-192a-4ab8-9903-ea0f393c35f7?as=iiif\"\n",
    "max_manifests = 5000\n",
    "\n",
    "manifest_ids, _collection_ids = client.get_manifests_and_collections_ids(collection_url, max_manifests)\n",
    "\n",
    "print(f\"ðŸ”Ž Found {len(manifest_ids)} manifests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f2df85",
   "metadata": {},
   "source": [
    "## Transforming data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd79a51",
   "metadata": {},
   "source": [
    "The next step is to transform the data into an instruction based format:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": \"\",\n",
    "    \"completion\": \"\"\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2ce2a1",
   "metadata": {},
   "source": [
    "<div style=\"border-radius: .5rem; border:2px solid #ac9a14; background-color: #ffe900; max-width: fit-content; max-height: fit-content; padding: 1rem; color: black; line-height: 1;\">\n",
    "It is not strictly necessary for the data to be in this format, but it provides conveniences later for fine tuning.\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ee487",
   "metadata": {},
   "source": [
    "Though the goal of the repo is to fine tune the style of a multimodal model:\n",
    "- it is not necessary to include images in the data, as the vision layer will not be adjsuted\n",
    "- the text can come from anywhere, hence using the `summary` of a `Manifest`; not the `description` of a `Canvas`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4061b0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Processed 4906 manifests\n",
      "Example:\n",
      "{\n",
      "  \"prompt\": \"Describe this image.\",\n",
      "  \"completion\": \"Sandy Paton playing guitar at Creed's Books in Berkeley, California\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "data = []\n",
    "\n",
    "for id in manifest_ids:\n",
    "    manifest = client.fetch_json(id)\n",
    "\n",
    "    if \"summary\" not in manifest:\n",
    "        continue\n",
    "\n",
    "    summary: dict = manifest[\"summary\"]\n",
    "    keys = summary.keys()\n",
    "\n",
    "    if len(keys) == 0:\n",
    "        continue\n",
    "\n",
    "    summary_text: str = \"\"\n",
    "    if \"none\" in keys:\n",
    "        summary_text = \"\\n\".join(summary[\"none\"])\n",
    "    else:\n",
    "        summary_text = \"\\n\".join(summary[keys[0]])\n",
    "\n",
    "    line = {\n",
    "        \"prompt\": \"Describe this image.\",\n",
    "        \"completion\": summary_text,\n",
    "    }\n",
    "\n",
    "    data.append(line)\n",
    "\n",
    "print(f\"âœ… Processed {len(data)} manifests\")\n",
    "print(\"Example:\")\n",
    "print(json.dumps(data[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee9de56",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813d2db9",
   "metadata": {},
   "source": [
    "### Local\n",
    "\n",
    "Save the data locally as a `.jsonl` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4889aa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"outputs.jsonl\"\n",
    "with open(file_name, \"w\") as f:\n",
    "    for i, line in enumerate(data):\n",
    "        if i != 0:\n",
    "            f.write(\"\\n\")\n",
    "        f.write(json.dumps(line))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f064cca",
   "metadata": {},
   "source": [
    "### Huggingface (Optional)\n",
    "\n",
    "Save the data to Huggingface as a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f2b95ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/charles/Documents/code/stylometry/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from huggingface_hub import login\n",
    "\n",
    "login(os.environ[\"HF_TOKEN\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ae382cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepoUrl('https://huggingface.co/datasets/charlesLoder/northwestern-metadata', endpoint='https://huggingface.co', repo_type='dataset', repo_id='charlesLoder/northwestern-metadata')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "# Change this to your own repo name\n",
    "new_repo_name = \"charlesLoder/northwestern-metadata\"\n",
    "api.create_repo(\n",
    "    repo_id=new_repo_name,\n",
    "    repo_type=\"dataset\",\n",
    "    private=True,\n",
    "    exist_ok=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5526619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/charlesLoder/northwestern-metadata/commit/0c5fe6fe00dbbf585c8bd6e6ba44f6d148f686e6', commit_message='Create dataset', commit_description='', oid='0c5fe6fe00dbbf585c8bd6e6ba44f6d148f686e6', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/charlesLoder/northwestern-metadata', endpoint='https://huggingface.co', repo_type='dataset', repo_id='charlesLoder/northwestern-metadata'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.upload_file(\n",
    "    path_or_fileobj=file_name,\n",
    "    path_in_repo=file_name,\n",
    "    repo_id=new_repo_name,\n",
    "    repo_type=\"dataset\",\n",
    "    commit_message=\"Create dataset\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
